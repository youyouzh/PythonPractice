# 图像分类基础

## 深度学习开源框架

### 深度学习开源框架的选择

深度学习相关的开源框架众多，为人熟知的有caffe，tensorflow，pytorch/caffe2，keras，mxnet，paddldpaddle，theano，cntk，deeplearning4j，matconvnet等。

1. 不管怎么说，tensorflow/pytorch你都必须会，这是目前开发者最喜欢，开源项目最丰富的两个框架。
2. 如果你要进行移动端算法的开发，那么Caffe是不能不会的。
3. 如果你非常熟悉Matlab，matconvnet你不应该错过。
4. 如果你追求高效轻量，那么darknet和mxnet你不能不熟悉。
5. 如果你很懒，想写最少的代码完成任务，那么用keras吧。
6. 如果你是java程序员，那么掌握deeplearning4j没错的。

### 深度学习开源框架的学习

要掌握好一个开源框架，通常需要做到以下几点：

1. 熟练掌握不同任务数据的准备和使用。
2. 熟练掌握模型的定义。
3. 熟练掌握训练过程和结果的可视化。
4. 熟练掌握训练方法和测试方法。

一个框架，官方都会开放有若干的案例，最常见的案例就是以**MNISI数据接口+预训练模型**的形式，供大家快速获得结果，但是这明显还不够，学习不应该停留在跑通官方的demo上，而是要解决实际的问题。

我们要学会从自定义数据读取接口，自定义网络的搭建，模型的训练，模型的可视化，模型的测试与部署等全方位进行掌握。

学习实践流程：

1. 准备数据
2. 定义网络
3. 训练
4. 可视化
5. 测试

### 开源框架介绍

- [Caffe](https://github.com/BVLC/caffe)
  - 概述
    - Caffe是伯克利的贾扬清主导开发，以C++/CUDA代码为主，最早的深度学习框架之一，比TensorFlow、Mxnet、Pytorch等都更早，需要进行编译安装。
    - 支持命令行、Python和Matlab接口，单机多卡、多机多卡等都可以很方便的使用。
    - 目前master分支已经停止更新，intel分支等还在维护，caffe框架已经非常稳定。
  - 优点：
    - 以C++/CUDA/python代码为主，速度快，性能高。
    - 工厂设计模式，代码结构清晰，可读性和拓展性强。
    - 支持命令行、Python和Matlab接口，使用方便。
    - CPU和GPU之间切换方便，多GPU训练方便。
    - 工具丰富，社区活跃。
  - 缺点：
    - 源代码修改门槛较高，需要实现前向反向传播，以及CUDA代码。
    - 不支持自动求导。
    - 不支持模型级并行，只支持数据级并行
    - 不适合于非图像任务。
- [Tensorflow](https://github.com/tensorflow/tensorflow) 143k
    - 概述
      - TensorFlow是Google brain推出的开源机器学习库，可用作各类深度学习相关的任务
      - TensorFlow = Tensor + Flow，Tensor就是张量，代表N维数组，这与Caffe中的blob是类似的；Flow即流，代表基于数据流图的计算
    - 特点
      - 最大的特点是计算图，即先定义好图，然后进行运算，所以所有的TensorFlow代码
      - 创建计算图，表示计算的数据流，可看做是Caffe中的prototxt的定义过程
      - 运行会话，执行图中的运算，可以看作是Caffe中的训练过程
      - TensorFlow的会话比Caffe灵活很多，由于是Python 接口，取中间结果分析，Debug等方便很多
    - 相关资料
      - 中文教程：<https://github.com/czy36mengfei/tensorflow2_tutorials_chinese>
      - 官网中文文档：<https://github.com/jikexueyuanwiki/tensorflow-zh>
- [Pytorch](https://github.com/pytorch/pytorch) star: 37.4K
  - 概述
    - 一句话总结Pytorch = Python + Torch
    - Torch是纽约大学的一个机器学习开源框架，几年前在学术界非常流行，包括Lecun等大佬都在使用
    - 使用Lua语言
    - 同TensorFlow一样，增加了自动求导
    - 后来Caffe2全部并入Pytorch，如今已经成为了非常流行的框架
    - 很多最新的研究如风格化、GAN等大多数采用Pytorch源码
  - 特点
    - 动态图计算，TensorFlow从静态图发展到了动态图机制Eager Execution，pytorch则一开始就是动态图机制
    - 动态图机制的好处就是随时随地修改，随处debug，没有类似编译的过程
    - 简单。相比TensorFlow1.0中Tensor、Variable、Session等概念充斥，数据读取接口频繁更新，tf.nn、tf.layers、tf.contrib各自重复
    - Pytorch则是从Tensor到Variable再到nn.Module，最新的Pytorch已经将Tensor和Variable合并，这分别就是从数据张量到网络的抽象层次的递进。
- [Keras](https://github.com/keras-team/keras) star: 47.5K
  - 概述
    - Keras是一个对小白用户非常友好而简单的深度学习框架，严格来说并不是一个开源框架，而是一个高度模块化的神经网络库
    - Keras在高层可以调用TensorFlow，CNTK，Theano，还有更多的库也在被陆续支持中
  - 特点
    - 高度模块化，搭建网络非常简洁
    - API很简单，具有统一的风格
    - 容易扩展，只需使用python添加新类和函数

## 数据可视化

可视化将数字抽象成了更方便我们观察和感受的图表。

### 低纬度数据可视化

- 散点图，常用于分析离散数据的分布
- 折线图，用于分析变量随另一个变量的变化关系
- 直方图，饼状图，都常用于统计数据的分布比例以及响应幅度

### 高纬度数据可视化

在机器学习任务中，数据通常是用成百上千维的向量表示，而超过 3 维的向量，就已经超过了人类的可视化认知，因此通常需要对数据进行降维。

数据降维方法可以分为线性方法和非线性方法。其中线性方法包括 PCA 和 LDA，而非线性方法有保留局部特征、基于全局特征等方法，以 t-SNE 为代表。

#### PCA 降维

PCA，全称是 Principal components analysis，这是一种分析、简化数据集的技术。

PCA 常用于减少数据集的维数，同时保持数据集中对方差贡献最大的特征，原理是保留低阶主成分，忽略高阶主成分，因为低阶成分保留了数据最多的信息。

#### t-SNE 降维

SNE 全称是 Stochastic Neighbor Embedding，它将数据点之间高维的欧氏距离转换为表示相似度的条件概率，目标是将高维数据映射到低维后，尽量保持数据点之间的空间结构，从而那些在高维空间里距离较远的点，在低维空间中依然保持较远的距离。

t-SNE 即 t-distributed stochastic neighbor embedding，t-SNE 用联合概率分布替代了 SNE 中的条件概率分布，解决了 SNE 的不对称问题。通过引入 t 分布，解决了同类别之间簇的拥挤问题。

t-SNE 方法实质上是一种聚类的方法，对于一个空间中的点，周围的其他点都是它的“邻居”，方法就是要试图使所有点具有相同数量的“邻居”。

t-SNE 经过学习收敛后，通过投影到 2 维或者 3 维的空间中可以判断一个数据集有没有很好的可分性，即是否同类之间间隔小，异类之间间隔大。如果在低维空间中具有可分性，则数据是可分的，如果不具有可分性，可能是数据不可分，也可能仅仅是因为不能投影到低维空间。

### python 数据可视化项目

- `tensorboard`和[`tensorboardX`](https://github.com/lanpa/tensorboardX)， 被开发用来支持 chainer, mxnet, numpy，4
- [`visdom`](https://github.com/facebookresearch/visdom)，支持 numpy 和 torch 的工具，常用于 pytorch 数据可视化
- [`seaborn`](https://github.com/mwaskom/seaborn)：一款基于于 matplotlib 的工具，简单来说，就是有更高的 API，画出的图也好看，5000+star，主要处理低维数据。
- [holoviews](https://github.com/ioam/holoviews)：很酷炫的工具，与season 差不多，
- [missingno](https://github.com/ResidentMario/missingno)：一款缺失数据可视化工具，非常适合分析数据集的完整性，

## 计算机视觉研究方向

- 图像分类
  - 二分类
    - 跨物种语义级图像分类
    - 子类细粒度图像分类
    - 实例级图像分类
  - 传统机器学习方法: 种经典的特征算子+经典分类器组合学习，比如 HoG+SVM
  - 深度学习方法：各种分类网络,ImageNet 竞赛
  - 图像分类的比赛基本落幕，也接近算法的极限
  - 实际的应用问题样本不均衡，分类界面模糊，未知类别
- 目标检测
  - 目标检测方向有一些固有的难题，比如小脸，遮挡，大姿态
  - 多尺度与级联网络的设计，难样本的挖掘，多任务 loss 等都是比较大的研究小方向
- 图像分割
  - 图像分割属于图像处理领域最高层次的图像理解范畴
  - 把图像分割成具有相似的颜色或纹理特性的若干子区域，并使它们对应不同的物体或物体的不同部分的技术
  - 这些子区域，组成图像的完备子集，又相互之间不重叠
  - 关键的技术：反卷积的使用，多尺度特征融合，多尺度与上下文信息，CRF 等后处理方法
- 目标跟踪
  - 根据目标跟踪方法建模方式的不同，可以分为生成式模型方法与判别式模型方法
  - 通过对原始影像帧，对目标及背景信息进行区分建立判别模型，通过对后续影像帧搜索目标进行判别是目标或背景信息进而完成目标跟踪。
- 图像滤波与降噪
- 图像增强
  - 增强图像中的有用信息，改善图像的视觉效果
  - 对比度增强，用于扩大图像中不同物体特征之间的差别，抑制不感兴趣的特征，可用于改善图像的识别效果，满足某些特殊分析
  - 超分辨，使图像变得更加清晰，可以用于视频的传输先进行降采样，再进行升采样，即降低了传输成本，又增加了视觉效果
  - 图像修复，重建图像和视频中丢失或损坏的部分
- 风格化
  - 研究者认为，图片可以由内容层（Content）与风格层（Style）两个图层᧿述，相互分离开
- 三维重建
- 图像检索
  - 基于内容的图像检索（Content-based Image Retrieval，简称 CBIR）技术
  - 深度学习在图像检索里面的作用就是把表征样本的特征学习好，就够了
- GAN
  - GAN，即 Generative adversarial net，被誉为新的深度学习，涉及的研究非常多，可以单列为一个方向
  - GAN 的原理很简单，它包括两个网络，一个生成网络，不断生成数据分布。一个判别网络，判断生成的数据是否为真实数据。

## 实践

- 图像相似度计算： <https://zhuanlan.zhihu.com/p/68215900>
  - 直方图计算图片的相似度
  - 通过哈希值，汉明距离计算
  - 通过图片的余弦距离计算
  - 通过图片结构度量计算：使用 skimage 的 compare_ssim
- 考虑提取图像特征
